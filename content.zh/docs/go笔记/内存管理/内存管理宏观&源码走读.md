---
title: "内存管理宏观&源码走读"
weight: 1
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: true
# bookComments: false
# bookSearchExclude: false
# bookHref: ''
# bookIcon: ''
---

# 内存管理宏观

## 操作系统内存管理

### 操作系统内存存储模型

![](/assets/内存管理宏观-1768878492121.png)
1. 多级存储 （寄存器 + cpu多级缓存（L1/L2/L3三级缓存） + 内存 + 磁盘存储（外存））
2. 动态切换（根据数据的访问频率和局部性，在各层级间动态迁移数据、切换存储位置—— 让高频热数据留在高速层（寄存器 / 缓存 / 主存），低频冷数据被置换到低速层（主存 / 磁盘）

### 操作系统内存管理机制

> 早期分页管理的目的是为了解决内存寻址和进程隔离问题。
> 
> - 内存离散分配：早期计算机是“连续内存分配”。提出“分页管理”，通过划分内存为固定大小的页，通过页表映射物理地址和页。实现离散的内存管理。
> - 进程隔离：进程有各自的页表，不同进程不可以访问非自己的页表

分页管理是操作系统实现内存管理的核心物理机制（将物理内存 / 磁盘划分为等大页，方便地址映射和管理）

**分页管理优点：**
- 提高内存利用（消除外部碎片，留下较为可控的内部碎片）
- 实现了进程隔离（进程有各自的页表，不同进程不可以访问非自己的页表）
- 内存/外存的交换效率和灵活性提高了
- 页/帧 大小固定（经验值：太粗会增加碎片率，太细会增加分配频率影响效率）
- 页表有利于进行虚拟地址到物理地址的映射

### 操作系统内存管理方法

> 后面，由于物理内存的不足，提出“虚拟内存”，通过虚拟化磁盘（磁盘作为物理内存的扩展），将磁盘分页管理，通过页面置换算法实现内外存的动态迁移，解决的是：物理内存不足的问题。
> 基于分页管理技术
> 扩展物理内存

之后，分页管理的作用就从 “内存寻址/进程隔离” 到 “有利于虚拟地址（等）”。从“物理内存”的分页管理到“物理内存/磁盘”的分页管理

虚拟内存是基于分页管理实现的内存抽象技术（让进程看到连续的虚拟地址空间，解耦进程与物理内存的直接关联）

**虚拟内存技术优点：**
- 解耦进程和物理内存
- 放大可用内存（通过磁盘补足 + 页面置换（冷热数据置换，用户无感知））

## Golang 内存管理

和操作系统的内存管理做对照，golang有哪些类似？又有哪些变化？

相同：
1. 多级缓存（一次缓存，多次复用）

### Golang 内存管理机制

![](/assets/内存管理宏观-1768881352589.png)

### 核心概念

#### mheap
- 全局唯一（加锁访问）
- 分配大对象
- go程序中所有对象的内存分配来源
```go
type mheap struct {
    // 堆的全局锁
    lock mutex


    // 空闲页分配器，底层是多棵基数树组成的索引，每棵树对应 16 GB 内存空间
    pages pageAlloc 


    // 记录了所有的 mspan. 需要知道，所有 mspan 都是经由 mheap，使用连续空闲页组装生成的
    allspans []*mspan


    // heapAreana 数组，64 位系统下，二维数组容量为 [1][2^22]
    // 每个 heapArena 大小 64M，因此理论上，Golang 堆上限为 2^22*64M = 256T
    arenas [1 << arenaL1Bits]*[1 << arenaL2Bits]*heapArena


    // ...
    // 多个 mcentral，总个数为 spanClass 的个数
    central [numSpanClasses]struct {
        mcentral mcentral
        // 用于内存地址对齐
        pad      [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte
    }


    // ...
}
```

1. heapArena(大粒度管理单元)：大小固定为 64MB
2. heapArena 核心作用是将 mheap 管理的海量虚拟地址空间划分为一个个 64MB 的「内存大区」，让内存元数据（如 page 状态、mspan 映射）的管理更高效，同时适配 64 位系统的超大地址空间特性

#### mcentral
- 数量 == 68（68种大小规格/等级） * 2（有无指针） = 136
- 根据类型，相同类型的内存区域放在一块
- 细琐（相对于mheap，同类型分配内存时加锁，锁的粒度更小）
- 标志/内存单元等级：spanClass（8位二进制数 = 7 位表示类型 + 1 位表示是否为指针）
```go
type mcentral struct {
	_         sys.NotInHeap
	spanclass spanClass

	// 这两分别表示有空闲槽和满（无）空闲槽
	// 分别都有两个集合 spanSet = swept + unswept
	// 二者轮流作为这两个角色，为了躲避一轮GC（躲避一轮互换角色）
	// 其中 unswept 是未清扫的，可能有未回收的垃圾对象，需要先GC
	// 这样就能使得 分配内存 + 回收垃圾 并行执行
	partial [2]spanSet // list of spans with a free object
	full    [2]spanSet // list of spans with no free objects
}
```
1. partial：里面的 mspan 有空闲槽位（能直接分配对象）
2. full：里面的 mspan 无空闲槽位（暂时不能分配，等对象回收后变回 partial）

虽然 full 暂时不能分配对象，但是由于随时都存在GC，回收对象后可以分配。因此也需要两个（一个：GC 已扫过，明确当前无空闲槽位；另一个：扫过才知道，可能回收对象后变为partial）

#### mcache
- 每个 P（正是 GMP 中的 P）持有一份的内存缓存（访问无锁）
```go
type mcache struct {
    // 微对象分配器相关
    tiny       uintptr
    tinyoffset uintptr
    tinyAllocs uintptr
    
    // mcache 中缓存的 mspan，每种 spanClass 各一个
    alloc [numSpanClasses]*mspan 
    // ...
}
```
1. tiny allocator 微对象处理器，用于处理小于 16B 对象的内存分配。

#### page
- 最小的存储单元（和操作系统一样）—— go中的页大小为 8 KB（64位）

#### mspan
- 最小的管理单元（将多个连续的页划分为一个mspan）
- mspan自身的大小是page的整数倍
- 规格不同：(源码：numSpanClasses = gc.NumSizeClasses << 1 == 68 * 2 = 136)
```text
第一档（≤256B）：8B 步长，8B、16B、24B...256B → 256/8 = 32 种；
第二档（256B~32KB）：2 倍步长，512B、1024B、2048B...32768B（32KB）→ 共 36 种；
总计：32 + 36 = 68 种
算上 有无指针（scan/noscan）共是136种
```

```go
type mspan struct {
    // 标识前后节点的指针 
    next *mspan     
    prev *mspan    
    // ...
    // 起始地址
    startAddr uintptr 
    // 包含几页，页是连续的
    npages    uintptr 


    // 标识此前的位置都已被占用 
    freeindex uintptr
    // 最多可以存放多少个 object
    nelems uintptr // number of object in the span.


    // bitmap 每个 bit 对应一个 object 块，标识该块是否已被占用
    allocCache uint64
    // ...
    // 标识 mspan 等级，包含 class 和 noscan 两部分信息
    spanclass             spanClass    
    // ...
}
```

**优点：**
1. 根据规格大小，有等级制度（支持细锁）
2. 消除外部碎片
3. 提高整体的空间利用率

#### 总结
- mheap只有一个
- mcentral存储不同类型mspan的分别有一个集合，共136个；
- mcache缓存mspan（内置136个槽位，每种规格各最多缓存一个）；
- mspan的种类对应的也有136个。

## Golang 内存分配流程

### 微对象(0 - 16B)

（1）从 P 专属 mcache 的 tiny 分配器取内存（无锁）

（2）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）

（3）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）

（4）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）

（5）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.

### 小对象(16B - 32KB)

（1）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）

（2）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）

（3）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）

（4）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.

### 大对象(32KB - 无穷)

（1）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）

（2）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.

### 分配对象流程源码

```go
// 小对象从每个P缓存的空闲列表中分配。
// 大对象（大于32 kB）直接从堆中分配。

//go:linkname mallocgc
func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer {
	if doubleCheckMalloc {
		if gcphase == _GCmarktermination {
			throw("mallocgc called with gcphase == _GCmarktermination")
		}
	}

	// 快速处理大小为0的分配请求
	if size == 0 {
		return unsafe.Pointer(&zerobase)
	}

	if sizeSpecializedMallocEnabled && heapBitsInSpan(size) {
		if typ == nil || !typ.Pointers() {
			return mallocNoScanTable[size](size, typ, needzero)
		} else {
			if !needzero {
				throw("objects with pointers must be zeroed")
			}
			return mallocScanTable[size](size, typ, needzero)
		}
	}

	// 记录动态锁依赖，未启用lockrank实验则编译优化掉
	lockRankMayQueueFinalizer()

	// 内存分配前的调试钩子，仅调试模式生效
	if debug.malloc {
		if x := preMallocgcDebug(size, typ); x != nil {
			return x
		}
	}

	// ASAN地址消毒剂：分配额外红区内存检测越界，标记为不可访问
	var asanRZ uintptr
	if asanenabled {
		asanRZ = redZoneSize(size)
		size += asanRZ
	}

	// 必要时协助GC执行，扣除GC辅助信用值
	if gcBlackenEnabled != 0 {
		deductAssistCredit(size)
	}

	//===========================实际分配===========================
	
	// 执行实际的内存分配逻辑
	var x unsafe.Pointer
	var elemsize uintptr
	if sizeSpecializedMallocEnabled {
		if size <= maxSmallSize-gc.MallocHeaderSize {
			// 小对象分配
			if typ == nil || !typ.Pointers() {
				// 无指针小对象
				x, elemsize = mallocgcSmallNoscan(size, typ, needzero)
			} else {
				if !needzero {
					throw("objects with pointers must be zeroed")
				}
				// 有指针小对象（带GC头）
				x, elemsize = mallocgcSmallScanHeader(size, typ)
			}
		} else {
			// 大对象分配
			x, elemsize = mallocgcLarge(size, typ, needzero)
		}
	} else {
		if size <= maxSmallSize-gc.MallocHeaderSize {
			// 小对象分配
			if typ == nil || !typ.Pointers() {
				// 极小对象分配优化，机密模式避开tiny分配器
				gp := getg()
				if size < maxTinySize && gp.secret == 0 {
					x, elemsize = mallocgcTiny(size, typ)
				} else {
					x, elemsize = mallocgcSmallNoscan(size, typ, needzero)
				}
			} else {
				if !needzero {
					throw("objects with pointers must be zeroed")
				}
				if heapBitsInSpan(size) {
					// 有指针小对象（无GC头）
					x, elemsize = mallocgcSmallScanNoHeader(size, typ)
				} else {
					// 有指针小对象（带GC头）
					x, elemsize = mallocgcSmallScanHeader(size, typ)
				}
			}
		} else {
			// 大对象直接走堆分配
			x, elemsize = mallocgcLarge(size, typ, needzero)
		}
	}

	// 机密模式分配：标记对象为机密，释放时立即清零防止数据泄露
	gp := getg()
	if goexperiment.RuntimeSecret && gp.secret > 0 {
		addSecret(x, size)
	}

	// 通知各类内存检测工具（若启用）
	if raceenabled {
		racemalloc(x, size-asanRZ)
	}
	if msanenabled {
		msanmalloc(x, size-asanRZ)
	}
	if asanenabled {
		// 毒化红区、解除业务内存毒化，检测内存越界
		frag := elemsize - size
		if typ != nil && typ.Pointers() && !heapBitsInSpan(elemsize) && size <= maxSmallSize-gc.MallocHeaderSize {
			frag -= gc.MallocHeaderSize
		}
		asanpoison(unsafe.Add(x, size-asanRZ), asanRZ)
		asanunpoison(x, size-asanRZ)
	}
	if valgrindenabled {
		valgrindMalloc(x, size-asanRZ)
	}

	// 调整GC辅助债务，抵消内存内部碎片的GC开销影响
	if gcBlackenEnabled != 0 && elemsize != 0 {
		if assistG := getg().m.curg; assistG != nil {
			assistG.gcAssistBytes -= int64(elemsize - size)
		}
	}

	// 内存分配后的调试钩子，仅调试模式生效
	if debug.malloc {
		postMallocgcDebug(x, elemsize, typ)
	}
	return x
}
```

**tiny对象分配：**

```
func mallocgcTiny(size uintptr, typ *_type) (unsafe.Pointer, uintptr) {
	// 将mp.mallocing置位，避免分配过程被GC抢占
	mp := acquirem()
	if doubleCheckMalloc {
		if mp.mallocing != 0 {
			throw("malloc deadlock")
		}
		if mp.gsignal == getg() {
			throw("malloc during signal")
		}
		if typ != nil && typ.Pointers() {
			throw("expected noscan for tiny alloc")
		}
	}
	mp.mallocing = 1

	// Tiny分配器核心逻辑
	//
	// Tiny分配器将多个极小的内存分配请求合并到单个内存块中
	// 只有当所有子对象都不可达时，整个内存块才会被释放
	// 子对象必须是noscan类型（不含指针），这能保证潜在的内存浪费处于可控范围
	//
	// 用于合并的内存块大小（maxTinySize）是可调节的
	// 当前设置为16字节，这会导致最坏情况下2倍的内存浪费（当除一个子对象外其余都不可达时）
	// 8字节设置不会产生任何浪费，但合并的机会更少
	// 32字节设置能提供更多合并机会，但最坏情况会导致4倍内存浪费
	// 无论块大小如何，最佳情况下能节省8倍内存
	//
	// 从tiny分配器获取的对象不能显式释放
	// 因此当一个对象需要被显式释放时，我们会确保其大小≥maxTinySize
	//
	// SetFinalizer针对可能来自tiny分配器的对象做了特殊处理
	// 允许为内存块中的单个字节区域设置析构函数
	//
	// Tiny分配器的主要优化目标是小字符串和独立的逃逸变量
	// 在json基准测试中，该分配器能减少约12%的分配次数，降低约20%的堆内存占用
	c := getMCache(mp)
	off := c.tinyoffset
	// 根据要求的（保守）对齐规则对齐tiny指针
	if size&7 == 0 {
		off = alignUp(off, 8)
	} else if goarch.PtrSize == 4 && size == 12 {
		// 在32位系统上，保守地将12字节对象对齐到8字节边界
		// 确保首个字段为64位值的对象能8字节对齐，避免原子访问时触发错误（参考issue 37262）
		// TODO(mknyszek)：若issue 36606解决，移除该兼容逻辑
		off = alignUp(off, 8)
	} else if size&3 == 0 {
		off = alignUp(off, 4)
	} else if size&1 == 0 {
		off = alignUp(off, 2)
	}
	if off+size <= maxTinySize && c.tiny != 0 {
		// 当前对象能放入已有的tiny内存块中
		x := unsafe.Pointer(c.tiny + off)
		c.tinyoffset = off + size
		c.tinyAllocs++
		mp.mallocing = 0
		releasem(mp)
		return x, 0
	}
	// 分配一个新的maxTinySize大小的内存块
	checkGCTrigger := false
	span := c.alloc[tinySpanClass]
	v := nextFreeFast(span)
	if v == 0 {
		v, span, checkGCTrigger = c.nextFree(tinySpanClass)
	}
	x := unsafe.Pointer(v)
	(*[2]uint64)(x)[0] = 0 // 始终清零
	(*[2]uint64)(x)[1] = 0
	// 根据剩余空闲空间大小，判断是否需要用新块替换现有tiny块
	if !raceenabled && (size < c.tinyoffset || c.tiny == 0) {
		// 注意：竞态检测器开启时该逻辑禁用（见函数末尾注释）
		c.tiny = uintptr(x)
		c.tinyoffset = size
	}

	// 确保上面初始化x为类型安全内存、设置堆位的写操作，
	// 在调用者将x暴露给垃圾回收器之前完成。
	// 否则在弱内存序架构下，垃圾回收器可能跟随指向x的指针，
	// 却看到未初始化的内存或过期的堆位信息。
	publicationBarrier()

	if writeBarrier.enabled {
		// GC期间分配的对象标记为黑色（无需扫描）
		// 所有槽位都存储nil，因此无需扫描
		// 这里可能与GC并发执行，因此需要原子操作标记位（若存在竞争）
		gcmarknewobject(span, uintptr(x))
	} else {
		// 记录标记阶段前的最后空闲索引，该字段仅被垃圾回收器使用
		// 标记阶段中，保守扫描器会用该字段过滤掉已释放且近期分配的对象
		// 这样做是安全的，因为GC启用时我们会将对象标记为黑色
		// 保守扫描器可能会凭空生成指针，若无额外同步机制，可能会观察到未完全初始化的对象，导致程序崩溃
		span.freeIndexForScan = span.freeindex
	}

	// 注意：仅在持有m的期间，缓存c才有效（参考#47302）
	// 
	// 注意：使用完整大小是因为这与GC在"释放"侧更新内存配置文件的方式一致
	// 
	// TODO(mknyszek)：实际上应该将头部计入gc_sys或其他字段
	// 下面的代码仅将其视为内部碎片，并通过使用整个分配槽位来匹配GC的统计方式
	c.nextSample -= int64(span.elemsize)
	if c.nextSample < 0 || MemProfileRate != c.memProfRate {
		profilealloc(mp, x, span.elemsize)
	}
	mp.mallocing = 0
	releasem(mp)

	if checkGCTrigger {
		if t := (gcTrigger{kind: gcTriggerHeap}); t.test() {
			gcStart(t)
		}
	}

	if raceenabled {
		// 对tiny大小的分配做内存填充，使其对齐到tiny分配区域的末尾
		// 确保任何超出对象顶端的内存操作都能被checkptr检测到（参考issue 38872）
		// 注意：为了实现该功能，竞态检测器开启时会禁用tiny分配器
		// TODO：该填充逻辑仅在竞态检测器开启时生效
		// 若有包编译时启用了checkptr，也应开启该逻辑，但目前无简单的检测方式（尤其是编译期）
		// TODO：为所有分配启用该填充逻辑，而不仅限于tiny分配
		// 但指针映射机制使其实现难度较大，或许可仅对noscan对象启用？
		x = add(x, span.elemsize-size)
	}
	return x, span.elemsize
}
```

**无指针小对象：**

```go
func mallocgcSmallNoscan(size uintptr, typ *_type, needzero bool) (unsafe.Pointer, uintptr) {
	// 将mp.mallocing置位，避免分配过程被GC抢占
	mp := acquirem()
	if doubleCheckMalloc {
		if mp.mallocing != 0 {
			throw("malloc deadlock")
		}
		if mp.gsignal == getg() {
			throw("malloc during signal")
		}
		if typ != nil && typ.Pointers() {
			throw("expected noscan type for noscan alloc")
		}
	}
	mp.mallocing = 1

	checkGCTrigger := false
	c := getMCache(mp)
	var sizeclass uint8
	if size <= gc.SmallSizeMax-8 {
		sizeclass = gc.SizeToSizeClass8[divRoundUp(size, gc.SmallSizeDiv)]
	} else {
		sizeclass = gc.SizeToSizeClass128[divRoundUp(size-gc.SmallSizeMax, gc.LargeSizeDiv)]
	}
	size = uintptr(gc.SizeClassToSize[sizeclass])
	spc := makeSpanClass(sizeclass, true)
	span := c.alloc[spc]

	// 优先检查是否有可复用的对象
	if runtimeFreegcEnabled && c.hasReusableNoscan(spc) {
		// 存在可复用对象，直接使用
		x := mallocgcSmallNoscanReuse(c, span, spc, size, needzero)
		mp.mallocing = 0
		releasem(mp)
		return x, size
	}

	v := nextFreeFast(span)
	if v == 0 {
		v, span, checkGCTrigger = c.nextFree(spc)
	}
	x := unsafe.Pointer(v)
	if needzero && span.needzero != 0 {
		memclrNoHeapPointers(x, size)
	}

	// 确保上面初始化x为类型安全内存、设置堆位的写操作，
	// 在调用者将x暴露给垃圾回收器之前完成。
	// 否则在弱内存序架构下，垃圾回收器可能跟随指向x的指针，
	// 却看到未初始化的内存或过期的堆位信息。
	publicationBarrier()

	if writeBarrier.enabled {
		// GC期间分配的对象标记为黑色（无需扫描）
		// 所有槽位都存储nil，因此无需扫描
		// 这里可能与GC并发执行，因此需要原子操作标记位（若存在竞争）
		gcmarknewobject(span, uintptr(x))
	} else {
		// 记录标记阶段前的最后空闲索引，该字段仅被垃圾回收器使用
		// 标记阶段中，保守扫描器会用该字段过滤掉已释放且近期分配的对象
		// 这样做是安全的，因为GC启用时我们会将对象标记为黑色
		// 保守扫描器可能会凭空生成指针，若无额外同步机制，可能会观察到未完全初始化的对象，导致程序崩溃
		span.freeIndexForScan = span.freeindex
	}

	// 注意：仅在持有m的期间，缓存c才有效（参考#47302）
	// 
	// 注意：使用完整大小是因为这与GC在"释放"侧更新内存配置文件的方式一致
	// 
	// TODO(mknyszek)：实际上应该将头部计入gc_sys或其他字段
	// 下面的代码仅将其视为内部碎片，并通过使用整个分配槽位来匹配GC的统计方式
	c.nextSample -= int64(size)
	if c.nextSample < 0 || MemProfileRate != c.memProfRate {
		profilealloc(mp, x, size)
	}
	mp.mallocing = 0
	releasem(mp)

	if checkGCTrigger {
		if t := (gcTrigger{kind: gcTriggerHeap}); t.test() {
			gcStart(t)
		}
	}
	return x, size
}
```

**有指针小对象：**

```go
func mallocgcSmallScanHeader(size uintptr, typ *_type) (unsafe.Pointer, uintptr) {
	// 将mp.mallocing置位，避免被GC抢占
	mp := acquirem()
	if doubleCheckMalloc {
		if mp.mallocing != 0 {
			throw("malloc deadlock")
		}
		if mp.gsignal == getg() {
			throw("malloc during signal")
		}
		if typ == nil || !typ.Pointers() {
			throw("noscan allocated in scan-only path")
		}
		if heapBitsInSpan(size) {
			throw("heap bits in span for header-only path")
		}
	}
	mp.mallocing = 1

	checkGCTrigger := false
	c := getMCache(mp)
	size += gc.MallocHeaderSize
	var sizeclass uint8
	if size <= gc.SmallSizeMax-8 {
		sizeclass = gc.SizeToSizeClass8[divRoundUp(size, gc.SmallSizeDiv)]
	} else {
		sizeclass = gc.SizeToSizeClass128[divRoundUp(size-gc.SmallSizeMax, gc.LargeSizeDiv)]
	}
	size = uintptr(gc.SizeClassToSize[sizeclass])
	spc := makeSpanClass(sizeclass, false)
	span := c.alloc[spc]
	v := nextFreeFast(span)
	if v == 0 {
		v, span, checkGCTrigger = c.nextFree(spc)
	}
	x := unsafe.Pointer(v)
	if span.needzero != 0 {
		memclrNoHeapPointers(x, size)
	}
	header := (**_type)(x)
	x = add(x, gc.MallocHeaderSize)
	c.scanAlloc += heapSetTypeSmallHeader(uintptr(x), size-gc.MallocHeaderSize, typ, header, span)

	// 确保上面初始化x为类型安全内存、设置堆位的写操作，
	// 在调用者将x暴露给垃圾回收器之前完成。
	// 否则在弱内存序架构下，垃圾回收器可能跟随指向x的指针，
	// 却看到未初始化的内存或过期的堆位信息。
	publicationBarrier()

	if writeBarrier.enabled {
		// GC期间分配的对象标记为黑色（无需扫描）
		// 所有槽位都存储nil，因此无需扫描
		// 这里可能与GC并发执行，因此需要原子操作标记位（若存在竞争）
		gcmarknewobject(span, uintptr(x))
	} else {
		// 记录标记阶段前的最后空闲索引，该字段仅被垃圾回收器使用
		// 标记阶段中，保守扫描器会用该字段过滤掉已释放且近期分配的对象
		// 这样做是安全的，因为GC启用时我们会将对象标记为黑色
		// 保守扫描器可能会凭空生成指针，若无额外同步机制，可能会观察到未完全初始化的对象，导致程序崩溃
		span.freeIndexForScan = span.freeindex
	}

	// 注意：仅在持有m的期间，缓存c才有效（参考#47302）
	// 
	// 注意：使用完整大小是因为这与GC在"释放"侧更新内存配置文件的方式一致
	// 
	// TODO(mknyszek)：实际上应该将头部计入gc_sys或其他字段
	// 下面的代码仅将其视为内部碎片，并通过使用整个分配槽位来匹配GC的统计方式
	c.nextSample -= int64(size)
	if c.nextSample < 0 || MemProfileRate != c.memProfRate {
		profilealloc(mp, x, size)
	}
	mp.mallocing = 0
	releasem(mp)

	if checkGCTrigger {
		if t := (gcTrigger{kind: gcTriggerHeap}); t.test() {
			gcStart(t)
		}
	}
	return x, size
}
```

**大对象分配：**
```go
func mallocgcLarge(size uintptr, typ *_type, needzero bool) (unsafe.Pointer, uintptr) {
    // 将mp.mallocing置位，避免被GC抢占
    mp := acquirem()
    if doubleCheckMalloc {
        if mp.mallocing != 0 {
            throw("malloc deadlock")
        }
        if mp.gsignal == getg() {
            throw("malloc during signal")
        }
    }
    mp.mallocing = 1

	c := getMCache(mp)
	// 对于大对象分配，记录内存的清零状态，以便后续在可抢占的上下文执行批量清零
	span := c.allocLarge(size, typ == nil || !typ.Pointers())
	span.freeindex = 1
	span.allocCount = 1
	span.largeType = nil // 告知GC暂时不要处理该对象
	size = span.elemsize
	x := unsafe.Pointer(span.base())

	// 确保上面将largeType设为nil的写操作，在调用者将x暴露给垃圾回收器之前完成
	// 
	// 否则在弱内存序架构下，垃圾回收器可能会跟随指向x的指针，却看到过期的largeType值
	publicationBarrier()

	if writeBarrier.enabled {
		// GC期间分配的对象标记为黑色（无需扫描）
		// 所有槽位都存储nil，因此无需扫描
		// 这里可能与GC并发执行，因此需要原子操作标记位（若存在竞争）
		gcmarknewobject(span, uintptr(x))
	} else {
		// 记录标记阶段前的最后空闲索引，该字段仅被垃圾回收器使用
		// 标记阶段中，保守扫描器会用该字段过滤掉已释放且近期分配的对象
		// 这样做是安全的，因为GC启用时我们会将对象标记为黑色
		// 保守扫描器可能会凭空生成指针，若无额外同步机制，可能会观察到未完全初始化的对象，导致程序崩溃
		span.freeIndexForScan = span.freeindex
	}

	// 注意：仅在持有m的期间，缓存c才有效（参考#47302）
	// 
	// 注意：使用完整大小是因为这与GC在"释放"侧更新内存配置文件的方式一致
	// 
	// TODO(mknyszek)：实际上应该将头部计入gc_sys或其他字段
	// 下面的代码仅将其视为内部碎片，并通过使用整个分配槽位来匹配GC的统计方式
	c.nextSample -= int64(size)
	if c.nextSample < 0 || MemProfileRate != c.memProfRate {
		profilealloc(mp, x, size)
	}
	mp.mallocing = 0
	releasem(mp)

	// 检查是否需要触发GC
	if t := (gcTrigger{kind: gcTriggerHeap}); t.test() {
		gcStart(t)
	}

	// 对象可在允许抢占的上下文延迟清零
	// 
	// x会保持内存存活状态
	if needzero && span.needzero != 0 {
		// 注意：此场景下size始终等于fullSize
		memclrNoHeapPointersChunked(size, x) // 此处可能触发抢占（参考#47302）
	}

	// 在不可抢占的状态下设置对象类型并执行发布屏障
	// 必须确保在heapSetTypeLarge和publicationBarrier之间不会被抢占
	// 否则在弱内存架构下，GC可能观察到未清零的内存但largeType已被设置
	// 
	// 若保守扫描错误地观察到部分分配的对象，也可能导致GC看到未清零的内存（参考上文freeIndexForScan的更新）
	// 这种情况由heapSetTypeLarge内部的同步机制处理
	mp = acquirem()
	if typ != nil && typ.Pointers() {
		// 确认内存已清零后，完成类型信息的存储
		getMCache(mp).scanAlloc += heapSetTypeLarge(uintptr(x), size, typ, span)
	}
	// 再次发布对象（此时内存已清零且类型信息已初始化）
	// 
	// 即使未更新任何类型信息，这一步也是必要的
	// 例如，x在无同步机制的情况下写入全局变量时，确保其他goroutine能看到已清零的内存
	publicationBarrier()
	releasem(mp)
	return x, size
}
```

